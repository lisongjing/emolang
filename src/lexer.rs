use unicode_segmentation::UnicodeSegmentation;

use crate::util::StatefulVector;

#[derive(Debug, PartialEq, Eq, Hash, Clone)]
pub enum TokenType {
    Illegal,
    Start,

    Assign,

    Plus,
    Minus,
    Multiply,
    Divide,
    Modulo,

    Equal,
    NotEqual,
    GreaterThan,
    GreaterThanOrEqual,
    LessThan,
    LessThanOrEqual,

    And,
    Or,
    Not,

    Comma,
    Semicolon,
    LParenthesis,
    RParenthesis,
    LBracket,
    RBracket,
    LBrace,
    RBrace,

    Identifier,

    True,
    False,

    If,
    Else,
    While,
    Function,
    Return,

    Integer,
    Float,
    String,
}

const RESERVED_SYMBOLS: [&str; 29] = [
    "â¬…ï¸", "â•", "â–", "âœ–ï¸", "â—", "ã€°ï¸", "ğŸŸ°", "â–¶ï¸", "â—€ï¸", "ğŸ”", "ğŸ”€", "â¸ï¸", "â†™ï¸", "ğŸ¦¶", "ğŸŒœ", "ğŸŒ›",
    "ğŸ‘‰", "ğŸ‘ˆ", "ğŸ«¸", "ğŸ«·", "ğŸ—¨ï¸", "ğŸ’¬", "âœ”ï¸", "âŒ", "â“", "â—", "â­•", "ğŸ“›", "ğŸ”™",
];
const DIGITALS: [&str; 10] = ["0ï¸âƒ£", "1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£", "4ï¸âƒ£", "5ï¸âƒ£", "6ï¸âƒ£", "7ï¸âƒ£", "8ï¸âƒ£", "9ï¸âƒ£"];
const DOTS: [&str; 9] = ["âšª", "âš«", "ğŸŸ¤", "ğŸŸ£", "ğŸ”µ", "ğŸŸ¢", "ğŸŸ¡", "ğŸŸ ", "ğŸ”´"];
const SPACES: [&str; 5] = [" ", "\t", "\r", "\n", "\r\n"];

#[derive(Debug, PartialEq, Clone)]
pub struct Token {
    pub token_type: TokenType,
    pub literal: String,
}

impl Token {
    pub fn from(token_type: TokenType, literal: String) -> Token {
        Token {
            token_type,
            literal,
        }
    }

    pub fn from_str(token_type: TokenType, literal: &str) -> Token {
        Self::from(token_type, String::from(literal))
    }

    pub fn start() -> Token {
        Token::from(TokenType::Start, String::new())
    }
}

pub struct Lexer<'a> {
    chars: StatefulVector<&'a str>,
}

impl <'a> Lexer<'a> {
    pub fn new(input: &'a str) -> Lexer<'a> {
        Lexer { chars: StatefulVector::from_vec(input.graphemes(true).collect::<Vec<&str>>()) }
    }

    pub fn tokenize(&mut self) -> StatefulVector<Token> {
        let mut tokens = StatefulVector::<Token>::new();
        let start_token = Token::start();
        tokens.push(start_token);
        self.chars.insert(0, " ");

        while let Some(char) = self.chars.to_next() {
            let token = match *char {
                "â¬…ï¸" => Token::from_str(TokenType::Assign, char),
                "â•" => Token::from_str(TokenType::Plus, char),
                "â–" => Token::from_str(TokenType::Minus, char),
                "âœ–ï¸" => Token::from_str(TokenType::Multiply, char),
                "â—" => Token::from_str(TokenType::Divide, char),
                "ã€°ï¸" => Token::from_str(TokenType::Modulo, char),
                "ğŸŸ°" => Token::from_str(TokenType::Equal, char),
                "â–¶ï¸" => self.handle_two_chars_token(TokenType::GreaterThan, "ğŸŸ°", TokenType::GreaterThanOrEqual),
                "â—€ï¸" => self.handle_two_chars_token(TokenType::LessThan, "ğŸŸ°", TokenType::LessThanOrEqual),
                "ğŸ”" => Token::from_str(TokenType::And, char),
                "ğŸ”€" => Token::from_str(TokenType::Or, char),
                "â¸ï¸" => Token::from_str(TokenType::Not, char),
                "â†™ï¸" => Token::from_str(TokenType::Semicolon, char),
                "âœ”ï¸" => Token::from_str(TokenType::True, char),
                "âŒ" => Token::from_str(TokenType::False, char),
                "â“" => Token::from_str(TokenType::If, char),
                "â—" => self.handle_two_chars_token(TokenType::Else, "ğŸŸ°", TokenType::NotEqual),
                "â­•" => Token::from_str(TokenType::While, char),
                "ğŸ“›" => Token::from_str(TokenType::Function, char),
                "ğŸ”™" => Token::from_str(TokenType::Return, char),
                "ğŸ¦¶" => Token::from_str(TokenType::Comma, char),
                "ğŸŒœ" => Token::from_str(TokenType::LParenthesis, char),
                "ğŸŒ›" => Token::from_str(TokenType::RParenthesis, char),
                "ğŸ‘‰" => Token::from_str(TokenType::LBracket, char),
                "ğŸ‘ˆ" => Token::from_str(TokenType::RBracket, char),
                "ğŸ«¸" => Token::from_str(TokenType::LBrace, char),
                "ğŸ«·" => Token::from_str(TokenType::RBrace, char),
                "ğŸ—¨ï¸" => self.handle_string(),
                _ if DIGITALS.contains(char) => self.handle_number(),
                _ if SPACES.contains(char) => continue,
                _ if is_identifier_char(char) => self.handle_identifier(),
                _ => Token::from_str(TokenType::Illegal, char),
            };
            tokens.push(token);
        }
        tokens
    }

    fn handle_two_chars_token(&mut self, single_char_token_type: TokenType, expected_next_char: &str, two_chars_token_type:TokenType) -> Token {
        let mut current_char = String::from(*self.chars.current().unwrap());
        let mut token_type = single_char_token_type;
        
        if self.chars.is_next_eq(&expected_next_char) {
            token_type = two_chars_token_type;
            current_char.push_str(self.chars.to_next().unwrap());
        }
        
        Token::from(token_type, current_char)
    }

    fn handle_string(&mut self) -> Token {
        let mut literal = String::new();
        while self.chars.to_next().is_some_and(|&char| char != "ğŸ’¬") {
            literal.push_str(self.chars.current().unwrap());
        }
        Token::from(TokenType::String, literal)
    }

    fn handle_number(&mut self) -> Token {
        let current_char = self.chars.current().unwrap().chars().next().unwrap();
        let mut literal = String::from(current_char);
        let mut token_type = TokenType::Integer;
        loop {
            let is_digital = self.chars.is_next_match(|char| DIGITALS.contains(char));
            let is_dot = self.chars.is_next_match(|char| DOTS.contains(char));

            if is_digital {
                let next_char = self.chars.to_next().unwrap();
                literal.push(next_char.chars().next().unwrap());
            } else if is_dot {
                self.chars.to_next().unwrap();
                token_type = TokenType::Float;
                literal.push('.');
            } else {
                break;
            }
        }
        Token::from(token_type, literal)
    }

    fn handle_identifier(&mut self) -> Token {
        let mut literal = String::from(*self.chars.current().unwrap());
        while self.chars.is_next_match(|char| is_identifier_char(char)) {
            literal.push_str(self.chars.to_next().unwrap());
        }
        Token::from(TokenType::Identifier, literal)
    }
}

fn is_identifier_char(char: &str) -> bool {
    !RESERVED_SYMBOLS.contains(&char)
        && !DIGITALS.contains(&char)
        && !DOTS.contains(&char)
        && !SPACES.contains(&char)
}


#[cfg(test)]
mod lexer_test {
    use super::*;

    #[test]
    fn test() {
        let source = String::from(
            "
        ãŠ™ï¸ğŸ”¢ â¬…ï¸ 3ï¸âƒ£âšª9ï¸âƒ£ âœ–ï¸ 2ï¸âƒ£ â†™ï¸
        ãŠ™ï¸ğŸ”¡ â¬…ï¸ ğŸ—¨ï¸ğŸˆ¶ğŸ…°ï¸ğŸˆšğŸ…±ï¸ğŸˆ²ğŸ†ğŸ’¬ â†™ï¸
        ğŸ“› ğŸˆ¯ ğŸŒœğŸ…°ï¸ğŸ¦¶ ğŸ…±ï¸ğŸŒ› ğŸ«¸
          â­• ğŸ…°ï¸ â–¶ï¸ğŸŸ° 0ï¸âƒ£ ğŸ” ğŸ…±ï¸ â—€ï¸ğŸŸ° 5ï¸âƒ£ ğŸ«¸
            ğŸ…°ï¸ â¬…ï¸ ğŸ…°ï¸ â• ğŸ…±ï¸ â†™ï¸
            ğŸ…±ï¸ â¬…ï¸ ğŸ…±ï¸ â– ğŸ…°ï¸ â†™ï¸
          ğŸ«·
          ğŸ”™ â“ ğŸ…°ï¸ â–¶ï¸ ğŸ…±ï¸ ğŸ«¸ğŸ…°ï¸ğŸ«· â— ğŸ«¸ğŸ…±ï¸ğŸ«· â†™ï¸
        ğŸ«·
        ğŸ…°ï¸ğŸ…±ï¸
        ",
        );
        let target = vec![
            Token::start(),
            Token::from_str(TokenType::Identifier, "ãŠ™ï¸ğŸ”¢"),
            Token::from_str(TokenType::Assign, "â¬…ï¸"),
            Token::from_str(TokenType::Float, "3.9"),
            Token::from_str(TokenType::Multiply, "âœ–ï¸"),
            Token::from_str(TokenType::Integer, "2"),
            Token::from_str(TokenType::Semicolon, "â†™ï¸"),
            Token::from_str(TokenType::Identifier, "ãŠ™ï¸ğŸ”¡"),
            Token::from_str(TokenType::Assign, "â¬…ï¸"),
            Token::from_str(TokenType::String, "ğŸˆ¶ğŸ…°ï¸ğŸˆšğŸ…±ï¸ğŸˆ²ğŸ†"),
            Token::from_str(TokenType::Semicolon, "â†™ï¸"),
            Token::from_str(TokenType::Function, "ğŸ“›"),
            Token::from_str(TokenType::Identifier, "ğŸˆ¯"),
            Token::from_str(TokenType::LParenthesis, "ğŸŒœ"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::Comma, "ğŸ¦¶"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::RParenthesis, "ğŸŒ›"),
            Token::from_str(TokenType::LBrace, "ğŸ«¸"),
            Token::from_str(TokenType::While, "â­•"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::GreaterThanOrEqual, "â–¶ï¸ğŸŸ°"),
            Token::from_str(TokenType::Integer, "0"),
            Token::from_str(TokenType::And, "ğŸ”"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::LessThanOrEqual, "â—€ï¸ğŸŸ°"),
            Token::from_str(TokenType::Integer, "5"),
            Token::from_str(TokenType::LBrace, "ğŸ«¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::Assign, "â¬…ï¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::Plus, "â•"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::Semicolon, "â†™ï¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::Assign, "â¬…ï¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::Minus, "â–"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::Semicolon, "â†™ï¸"),
            Token::from_str(TokenType::RBrace, "ğŸ«·"),
            Token::from_str(TokenType::Return, "ğŸ”™"),
            Token::from_str(TokenType::If, "â“"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::GreaterThan, "â–¶ï¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::LBrace, "ğŸ«¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸"),
            Token::from_str(TokenType::RBrace, "ğŸ«·"),
            Token::from_str(TokenType::Else, "â—"),
            Token::from_str(TokenType::LBrace, "ğŸ«¸"),
            Token::from_str(TokenType::Identifier, "ğŸ…±ï¸"),
            Token::from_str(TokenType::RBrace, "ğŸ«·"),
            Token::from_str(TokenType::Semicolon, "â†™ï¸"),
            Token::from_str(TokenType::RBrace, "ğŸ«·"),
            Token::from_str(TokenType::Identifier, "ğŸ…°ï¸ğŸ…±ï¸"),
        ];
        let mut lexer = Lexer::new(&source);
        assert_eq!(lexer.tokenize().to_vec(), target);
    }
}
