use unicode_segmentation::UnicodeSegmentation;

#[derive(Debug, PartialEq)]
enum TokenType {
    Illegal,
    End,
    
    Assign,
    
    Plus,
    Minus,
    Multiply,
    Divide,

    Equal,
    GreaterThan,
    LessThan,

    And,
    Or,
    Not,

    Semicolon,
    LBrace,
    RBrace,
    
    Identifier,

    True,
    False,
    
    Number,
}

const SYMBOLS: [&str; 18] = ["‚¨ÖÔ∏è", "‚ûï", "‚ûñ", "‚úñÔ∏è", "‚ûó", "üü∞", "‚ñ∂Ô∏è", "‚óÄÔ∏è", "üîÅ", "üîÄ", "‚è∏Ô∏è", "‚ÜôÔ∏è", "üëâ", "üëà", "üó®Ô∏è", "üí¨", "‚úîÔ∏è", "‚ùå"];
const DIGITALS: [&str; 11] = ["0Ô∏è‚É£", "1Ô∏è‚É£", "2Ô∏è‚É£", "3Ô∏è‚É£", "4Ô∏è‚É£", "5Ô∏è‚É£", "6Ô∏è‚É£", "7Ô∏è‚É£", "8Ô∏è‚É£", "9Ô∏è‚É£", "üîü"];
const DOTS: [&str; 9] = ["‚ö™", "‚ö´", "üü§", "üü£", "üîµ", "üü¢", "üü°", "üü†", "üî¥"];
const SPACES: [&str; 4] = [" ", "\t", "\r", "\n"];

pub struct Lexer {
    input: String,
}

impl Lexer {
    pub fn new(input: String) -> Lexer {
        Lexer { input }
    }
    
    pub fn tokenize(&self) -> Vec<Token> {
        let chars = self.input.graphemes(true).collect::<Vec<&str>>();
        let mut pos = 0usize;
        let mut tokens = vec![];

        while pos < chars.len() {
            let char = chars[pos];
            let token = match char {
                "‚¨ÖÔ∏è" => Token::from_str(TokenType::Assign, char),
                "‚ûï" => Token::from_str(TokenType::Plus, char),
                "‚ûñ" => Token::from_str(TokenType::Minus, char),
                "‚úñÔ∏è" => Token::from_str(TokenType::Multiply, char),
                "‚ûó" => Token::from_str(TokenType::Divide, char),
                "üü∞" => Token::from_str(TokenType::Equal, char),
                "‚ñ∂Ô∏è" => Token::from_str(TokenType::GreaterThan, char),
                "‚óÄÔ∏è" => Token::from_str(TokenType::LessThan, char),
                "üîÅ" => Token::from_str(TokenType::And, char),
                "üîÄ" => Token::from_str(TokenType::Or, char),
                "‚è∏Ô∏è" => Token::from_str(TokenType::Not, char),
                "‚ÜôÔ∏è" => Token::from_str(TokenType::Semicolon, char),
                "‚úîÔ∏è" => Token::from_str(TokenType::True, char),
                "‚ùå" => Token::from_str(TokenType::False, char),
                "üëâ" => Token::from_str(TokenType::LBrace, char),
                "üëà" => Token::from_str(TokenType::RBrace, char),
                _ if DIGITALS.contains(&char) => handle_number(&chars, pos),
                _ if SPACES.contains(&char) => { pos += 1; continue },
                _ if is_identifier_char(char) => handle_identifier(&chars, pos),
                _ => Token::from(TokenType::Illegal, String::new()),
            };
            pos += 1;
            tokens.push(token);
        }
        tokens
    }
}

fn handle_number(chars: &Vec<&str>, mut pos: usize) -> Token {
    let start = pos;
    let mut literal = String::from(chars[start]);
    while DIGITALS.contains(&chars[pos + 1]) || DOTS.contains(&chars[pos + 1]) {
        pos += 1;
        literal.push_str(chars[pos]);
    };
    Token::from(TokenType::Number, literal)
}

fn handle_identifier(chars: &Vec<&str>, mut pos: usize) -> Token {
    let start = pos;
    let mut literal = String::from(chars[start]);
    while is_identifier_char(&chars[pos + 1]) {
        pos += 1;
        literal.push_str(chars[pos]);
    };
    Token::from(TokenType::Identifier, literal)
}

fn is_identifier_char(char: &str) -> bool {
    !SYMBOLS.contains(&char) && !DIGITALS.contains(&char) && !DOTS.contains(&char) && !SPACES.contains(&char)
}

#[derive(Debug, PartialEq)]
pub struct Token {
    token_type: TokenType,
    literal: String,
}

impl Token {
    fn from(token_type: TokenType, literal: String) -> Token {
        Token { token_type, literal }
    }

    fn from_str(token_type: TokenType, literal: &str) -> Token {
        Self::from(token_type, String::from(literal))
    }
}


#[cfg(test)]
mod lexer_test {
    use super::*;

    #[test]
    fn test() {
        let source = String::from("„äôÔ∏è ‚¨ÖÔ∏è 3Ô∏è‚É£ ‚úñÔ∏è 2Ô∏è‚É£ ");
        let target = vec![Token::from_str(TokenType::Identifier, "„äôÔ∏è"), Token::from_str(TokenType::Assign, "‚¨ÖÔ∏è"), Token::from_str(TokenType::Number, "3Ô∏è‚É£"), Token::from_str(TokenType::Multiply, "‚úñÔ∏è"), Token::from_str(TokenType::Number, "2Ô∏è‚É£")];
        let lexer = Lexer::new(source);
        assert_eq!(lexer.tokenize(), target);
    }
}